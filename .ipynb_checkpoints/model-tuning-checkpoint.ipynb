{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a80a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8082fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819a7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV file\n",
    "df = pd.read_csv('data_FraudDetection_JAR2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc265975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fyear</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>p_aaer</th>\n",
       "      <th>misstate</th>\n",
       "      <th>act</th>\n",
       "      <th>ap</th>\n",
       "      <th>at</th>\n",
       "      <th>ceq</th>\n",
       "      <th>che</th>\n",
       "      <th>cogs</th>\n",
       "      <th>...</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>issue</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>1009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10.047</td>\n",
       "      <td>3.736</td>\n",
       "      <td>32.335</td>\n",
       "      <td>6.262</td>\n",
       "      <td>0.002</td>\n",
       "      <td>30.633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312448</td>\n",
       "      <td>0.095082</td>\n",
       "      <td>0.082631</td>\n",
       "      <td>-0.019761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413170</td>\n",
       "      <td>0.873555</td>\n",
       "      <td>0.167620</td>\n",
       "      <td>0.161961</td>\n",
       "      <td>-0.042140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>1011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.803</td>\n",
       "      <td>7.784</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315904</td>\n",
       "      <td>0.188832</td>\n",
       "      <td>-0.211389</td>\n",
       "      <td>-0.117832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157887</td>\n",
       "      <td>0.745139</td>\n",
       "      <td>-0.428957</td>\n",
       "      <td>-0.157888</td>\n",
       "      <td>0.100228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>1017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>55.040</td>\n",
       "      <td>3.601</td>\n",
       "      <td>118.120</td>\n",
       "      <td>44.393</td>\n",
       "      <td>3.132</td>\n",
       "      <td>107.343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605342</td>\n",
       "      <td>0.097551</td>\n",
       "      <td>-0.105780</td>\n",
       "      <td>0.091206</td>\n",
       "      <td>1</td>\n",
       "      <td>2.231337</td>\n",
       "      <td>1.015131</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.063681</td>\n",
       "      <td>0.066348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fyear  gvkey  p_aaer  misstate     act     ap       at     ceq    che  \\\n",
       "0   1990   1009     NaN         0  10.047  3.736   32.335   6.262  0.002   \n",
       "1   1990   1011     NaN         0   1.247  0.803    7.784   0.667  0.171   \n",
       "2   1990   1017     NaN         0  55.040  3.601  118.120  44.393  3.132   \n",
       "\n",
       "      cogs  ...  soft_assets     ch_cs     ch_cm    ch_roa  issue        bm  \\\n",
       "0   30.633  ...     0.312448  0.095082  0.082631 -0.019761      1  0.413170   \n",
       "1    1.125  ...     0.315904  0.188832 -0.211389 -0.117832      1  0.157887   \n",
       "2  107.343  ...     0.605342  0.097551 -0.105780  0.091206      1  2.231337   \n",
       "\n",
       "        dpi      reoa      EBIT    ch_fcf  \n",
       "0  0.873555  0.167620  0.161961 -0.042140  \n",
       "1  0.745139 -0.428957 -0.157888  0.100228  \n",
       "2  1.015131  0.394768  0.063681  0.066348  \n",
       "\n",
       "[3 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4507b43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fyear', 'gvkey', 'p_aaer', 'misstate', 'act', 'ap', 'at', 'ceq', 'che',\n",
       "       'cogs', 'csho', 'dlc', 'dltis', 'dltt', 'dp', 'ib', 'invt', 'ivao',\n",
       "       'ivst', 'lct', 'lt', 'ni', 'ppegt', 'pstk', 're', 'rect', 'sale',\n",
       "       'sstk', 'txp', 'txt', 'xint', 'prcc_f', 'dch_wc', 'ch_rsst', 'dch_rec',\n",
       "       'dch_inv', 'soft_assets', 'ch_cs', 'ch_cm', 'ch_roa', 'issue', 'bm',\n",
       "       'dpi', 'reoa', 'EBIT', 'ch_fcf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc372831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns to use as features\n",
    "features = ['act', 'ap', 'at', 'ceq', 'che', 'cogs', 'csho', 'dlc', 'dltis', 'dltt', 'dp', 'ib', 'invt', 'ivao', 'ivst', 'lct', 'lt', 'ni', 'ppegt', 'pstk', 're', 'rect',\n",
    "            'sale', 'sstk', 'txp', 'txt', 'xint', 'prcc_f', 'dch_wc', 'ch_rsst', 'dch_rec', 'dch_inv', 'soft_assets', 'ch_cs', 'ch_cm', 'ch_roa', 'bm', 'dpi', 'reoa', 'EBIT', 'ch_fcf','issue']\n",
    "\n",
    "raw_financial_items_28 = ['act', 'ap', 'at', 'ceq', 'che', 'cogs', 'csho', 'dlc', 'dltis', 'dltt', 'dp', 'ib', 'invt', 'ivao', 'ivst', 'lct', 'lt', 'ni', 'ppegt', 'pstk', 're', 'rect',\n",
    "            'sale', 'sstk', 'txp', 'txt', 'xint', 'prcc_f']\n",
    "\n",
    "financial_ratios_14 = ['dch_wc', 'ch_rsst', 'dch_rec', 'dch_inv', 'soft_assets', 'ch_cs', 'ch_cm', 'ch_roa', 'bm', 'dpi', 'reoa', 'EBIT', 'ch_fcf','issue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4fdae261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "act       0\n",
       "ap        0\n",
       "at        0\n",
       "ceq       0\n",
       "che       0\n",
       "cogs      0\n",
       "csho      0\n",
       "dlc       0\n",
       "dltis     0\n",
       "dltt      0\n",
       "dp        0\n",
       "ib        0\n",
       "invt      0\n",
       "ivao      0\n",
       "ivst      0\n",
       "lct       0\n",
       "lt        0\n",
       "ni        0\n",
       "ppegt     0\n",
       "pstk      0\n",
       "re        0\n",
       "rect      0\n",
       "sale      0\n",
       "sstk      0\n",
       "txp       0\n",
       "txt       0\n",
       "xint      0\n",
       "prcc_f    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[raw_financial_items_28].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1c3c2053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dch_wc          4759\n",
       "ch_rsst         4851\n",
       "dch_rec         4743\n",
       "dch_inv         4615\n",
       "soft_assets      592\n",
       "ch_cs          15918\n",
       "ch_cm          17107\n",
       "ch_roa         12678\n",
       "bm                18\n",
       "dpi             9228\n",
       "reoa             591\n",
       "EBIT             591\n",
       "ch_fcf          5407\n",
       "issue              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[financial_ratios_14].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ef263e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dch_wc</th>\n",
       "      <th>ch_rsst</th>\n",
       "      <th>dch_rec</th>\n",
       "      <th>dch_inv</th>\n",
       "      <th>soft_assets</th>\n",
       "      <th>ch_cs</th>\n",
       "      <th>ch_cm</th>\n",
       "      <th>ch_roa</th>\n",
       "      <th>bm</th>\n",
       "      <th>dpi</th>\n",
       "      <th>reoa</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>ch_fcf</th>\n",
       "      <th>issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072195</td>\n",
       "      <td>0.093950</td>\n",
       "      <td>0.309468</td>\n",
       "      <td>2.255857</td>\n",
       "      <td>-0.351043</td>\n",
       "      <td>0.026031</td>\n",
       "      <td>0.460195</td>\n",
       "      <td>1.180657</td>\n",
       "      <td>0.250241</td>\n",
       "      <td>0.115694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.034304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.791459</td>\n",
       "      <td>-1.671689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252746</td>\n",
       "      <td>0.991532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034184</td>\n",
       "      <td>0.219229</td>\n",
       "      <td>0.151757</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>0.019983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084244</td>\n",
       "      <td>-0.018568</td>\n",
       "      <td>0.790887</td>\n",
       "      <td>0.987211</td>\n",
       "      <td>-0.165315</td>\n",
       "      <td>-0.023623</td>\n",
       "      <td>1.054388</td>\n",
       "      <td>0.826361</td>\n",
       "      <td>-0.405198</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765263</td>\n",
       "      <td>-0.998884</td>\n",
       "      <td>-2.122524</td>\n",
       "      <td>-0.542159</td>\n",
       "      <td>0.887674</td>\n",
       "      <td>1.216388</td>\n",
       "      <td>-12.407675</td>\n",
       "      <td>-0.616995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145774</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.937457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.105019</td>\n",
       "      <td>-0.009988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145821</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.101880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050989</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.599718</td>\n",
       "      <td>-0.876563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.402487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.212378</td>\n",
       "      <td>-0.089157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145979</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.230125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.439220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.241512</td>\n",
       "      <td>0.130969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4851 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dch_wc  ch_rsst   dch_rec   dch_inv  soft_assets     ch_cs     ch_cm  \\\n",
       "506        NaN      NaN  0.072195  0.093950     0.309468  2.255857 -0.351043   \n",
       "595        NaN      NaN       NaN       NaN     0.902506       NaN       NaN   \n",
       "1200       NaN      NaN       NaN  0.252746     0.991532       NaN       NaN   \n",
       "1601       NaN      NaN -0.084244 -0.018568     0.790887  0.987211 -0.165315   \n",
       "2151       NaN      NaN  0.127701  0.000000     0.765263 -0.998884 -2.122524   \n",
       "...        ...      ...       ...       ...          ...       ...       ...   \n",
       "145774     NaN      NaN       NaN       NaN     0.004515       NaN       NaN   \n",
       "145821     NaN      NaN       NaN       NaN     0.993599       NaN       NaN   \n",
       "145924     NaN      NaN       NaN       NaN     0.835009       NaN       NaN   \n",
       "145974     NaN      NaN       NaN       NaN     0.776411       NaN       NaN   \n",
       "145979     NaN      NaN       NaN       NaN     0.230125       NaN       NaN   \n",
       "\n",
       "          ch_roa        bm       dpi       reoa      EBIT  ch_fcf  issue  \n",
       "506     0.026031  0.460195  1.180657   0.250241  0.115694     NaN      1  \n",
       "595          NaN -7.034304       NaN  -2.791459 -1.671689     NaN      0  \n",
       "1200   -0.034184  0.219229  0.151757  -0.015701  0.019983     NaN      1  \n",
       "1601   -0.023623  1.054388  0.826361  -0.405198  0.031624     NaN      1  \n",
       "2151   -0.542159  0.887674  1.216388 -12.407675 -0.616995     NaN      1  \n",
       "...          ...       ...       ...        ...       ...     ...    ...  \n",
       "145774       NaN  4.937457       NaN  -0.105019 -0.009988     NaN      0  \n",
       "145821       NaN  1.101880       NaN   0.050989  0.059279     NaN      1  \n",
       "145924       NaN  0.300968       NaN  -4.599718 -0.876563     NaN      1  \n",
       "145974       NaN  0.402487       NaN  -0.212378 -0.089157     NaN      1  \n",
       "145979       NaN  0.439220       NaN  -0.241512  0.130969     NaN      1  \n",
       "\n",
       "[4851 rows x 14 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[financial_ratios_14][df[financial_ratios_14]['ch_rsst'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7550826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bfb92d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146045, 46)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd70efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a8b629",
   "metadata": {},
   "source": [
    "### Distinct Training and Testing Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b6055086",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ce78d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[(data['fyear'] >=1991 ) & (data['fyear'] <= 1999)]\n",
    "validation_data = data[(data['fyear'] >= 2000 ) & (data['fyear'] <= 2001)]\n",
    "test_data = data[(data['fyear'] >= 2003 ) & (data['fyear'] <= 2008)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a6bd4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count positive and negative cases\n",
    "train_misstate_1 = train_data['misstate'].value_counts()[1]\n",
    "test_misstate_1 = test_data['misstate'].value_counts()[1]\n",
    "train_misstate_0 = train_data['misstate'].value_counts()[0]\n",
    "test_misstate_0 = test_data['misstate'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d83003c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives cases training:  332\n",
      "Positives cases test:  261\n",
      "Negative case training:  53720\n",
      "Negative case test:  34905\n"
     ]
    }
   ],
   "source": [
    "print(f\"Positives cases training: \", train_misstate_1)\n",
    "print(f\"Positives cases test: \", test_misstate_1)\n",
    "print(f\"Negative case training: \", train_misstate_0)\n",
    "print(f\"Negative case test: \", test_misstate_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fffd4d",
   "metadata": {},
   "source": [
    "#### For all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "220f101d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    332\n",
       "1    332\n",
       "Name: misstate, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27605306",
   "metadata": {},
   "source": [
    "## For 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1d83b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_neurons = [(40,50),(40,60),(50,70),(40,70),(50,90)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e202b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing data into features and labels\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['misstate']\n",
    "\n",
    "X_valid = validation_data[features]\n",
    "y_val = validation_data['misstate']\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data['misstate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "70c3dc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in train set: 664\n"
     ]
    }
   ],
   "source": [
    "X_train.shape\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Number of observations in train set: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919074f",
   "metadata": {},
   "source": [
    "### For all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "604d0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_mlp(inputs,i,j,X_train, y_train):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(inputs, i,j),\n",
    "                            random_state=42,\n",
    "                            verbose=False,\n",
    "                            learning_rate_init=0.003,\n",
    "                            activation='logistic')\n",
    "\n",
    "    # Fit data onto the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make prediction on test dataset\n",
    "    ypred = clf.predict(X_test)\n",
    "    auc = metrics.roc_auc_score(y_test, ypred)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, ypred)\n",
    "    TN, FP, FN, TP = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]  # True negatives ,False positives, False negatives, True positives\n",
    "    \n",
    "    return (auc,(TN, FP, FN, TP))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "99b44cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════╤═══════════════════╤══════════╤═══════╤═══════╤══════╤══════╕\n",
      "│   Neurons in HL-1 │   Neurons in HL-2 │      AUC │    TN │    FP │   FN │   TP │\n",
      "╞═══════════════════╪═══════════════════╪══════════╪═══════╪═══════╪══════╪══════╡\n",
      "│                40 │                50 │ 0.615292 │ 19951 │ 14954 │   89 │  172 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                60 │ 0.62822  │ 21121 │ 13784 │   91 │  170 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                70 │ 0.617557 │ 25726 │  9179 │  131 │  130 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                70 │ 0.624743 │ 21012 │ 13893 │   92 │  169 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                90 │ 0.602639 │ 22946 │ 11959 │  118 │  143 │\n",
      "╘═══════════════════╧═══════════════════╧══════════╧═══════╧═══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "column1,column2,column3,column4,column5,column6, column7= [],[],[],[],[],[],[]\n",
    "\n",
    "for i,j in hidden_layer_neurons:\n",
    "    auc,params = two_layer_mlp(42,i,j,X_train_resampled, y_train_resampled)\n",
    "    column1.append(i)\n",
    "    column2.append(j)\n",
    "    column3.append(auc)\n",
    "    column4.append(params[0])\n",
    "    column5.append(params[1])\n",
    "    column6.append(params[2])\n",
    "    column7.append(params[3])\n",
    "    \n",
    "#list of lists for the rows\n",
    "columns = list(zip(column1, column2, column3, column4, column5, column6, column7))\n",
    "\n",
    "#headers for each column\n",
    "headers = ['Neurons in HL-1', 'Neurons in HL-2', 'AUC', 'TN', 'FP', 'FN','TP']\n",
    "\n",
    "#table using the tabulate function\n",
    "table = tabulate(columns, headers, tablefmt=\"fancy_grid\")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6940ad",
   "metadata": {},
   "source": [
    "### For raw financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2906a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in train set: 664\n"
     ]
    }
   ],
   "source": [
    "# Split the training and testing data into features and labels\n",
    "X_train = train_data[raw_financial_items_28]\n",
    "y_train = train_data['misstate']\n",
    "\n",
    "X_valid = validation_data[raw_financial_items_28]\n",
    "y_val = validation_data['misstate']\n",
    "\n",
    "X_test = test_data[raw_financial_items_28]\n",
    "y_test = test_data['misstate'] \n",
    "\n",
    "X_train.shape\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Number of observations in train set: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9c7d65d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════╤═══════════════════╤══════════╤═══════╤═══════╤══════╤══════╕\n",
      "│   Neurons in HL-1 │   Neurons in HL-2 │      AUC │    TN │    FP │   FN │   TP │\n",
      "╞═══════════════════╪═══════════════════╪══════════╪═══════╪═══════╪══════╪══════╡\n",
      "│                40 │                50 │ 0.624215 │ 22045 │ 12860 │  100 │  161 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                60 │ 0.605036 │ 26858 │  8047 │  146 │  115 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                70 │ 0.627567 │ 24820 │ 10085 │  119 │  142 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                70 │ 0.605795 │ 23835 │ 11070 │  123 │  138 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                90 │ 0.607225 │ 24871 │ 10034 │  130 │  131 │\n",
      "╘═══════════════════╧═══════════════════╧══════════╧═══════╧═══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "column1,column2,column3,column4,column5,column6, column7= [],[],[],[],[],[],[]\n",
    "\n",
    "for i,j in hidden_layer_neurons:\n",
    "    auc,params = two_layer_mlp(28,i,j,X_train_resampled, y_train_resampled)\n",
    "    column1.append(i)\n",
    "    column2.append(j)\n",
    "    column3.append(auc)\n",
    "    column4.append(params[0])\n",
    "    column5.append(params[1])\n",
    "    column6.append(params[2])\n",
    "    column7.append(params[3])\n",
    "    \n",
    "#list of lists for the rows\n",
    "columns = list(zip(column1, column2, column3, column4, column5, column6, column7))\n",
    "\n",
    "#headers for each column\n",
    "headers = ['Neurons in HL-1', 'Neurons in HL-2', 'AUC', 'TN', 'FP', 'FN','TP']\n",
    "\n",
    "#table using the tabulate function\n",
    "table = tabulate(columns, headers, tablefmt=\"fancy_grid\")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447286d8",
   "metadata": {},
   "source": [
    "#### Financial ratios only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "edad9cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in train set: 664\n"
     ]
    }
   ],
   "source": [
    "# Split the training and testing data into features and labels\n",
    "X_train = train_data[financial_ratios_14]\n",
    "y_train = train_data['misstate']\n",
    "\n",
    "X_valid = validation_data[financial_ratios_14]\n",
    "y_val = validation_data['misstate']\n",
    "\n",
    "X_test = test_data[financial_ratios_14]\n",
    "y_test = test_data['misstate'] \n",
    "\n",
    "X_train.shape\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Number of observations in train set: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5619302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════╤═══════════════════╤══════════╤═══════╤═══════╤══════╤══════╕\n",
      "│   Neurons in HL-1 │   Neurons in HL-2 │      AUC │    TN │    FP │   FN │   TP │\n",
      "╞═══════════════════╪═══════════════════╪══════════╪═══════╪═══════╪══════╪══════╡\n",
      "│                40 │                50 │ 0.626636 │ 26761 │  8144 │  134 │  127 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                60 │ 0.630992 │ 23588 │ 11317 │  108 │  153 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                70 │ 0.623654 │ 24948 │  9957 │  122 │  139 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                70 │ 0.594693 │ 27607 │  7298 │  157 │  104 │\n",
      "├───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                90 │ 0.621879 │ 25894 │  9011 │  130 │  131 │\n",
      "╘═══════════════════╧═══════════════════╧══════════╧═══════╧═══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "column1,column2,column3,column4,column5,column6, column7= [],[],[],[],[],[],[]\n",
    "\n",
    "for i,j in hidden_layer_neurons:\n",
    "    auc,params = two_layer_mlp(14,i,j,X_train_resampled, y_train_resampled)\n",
    "    column1.append(i)\n",
    "    column2.append(j)\n",
    "    column3.append(auc)\n",
    "    column4.append(params[0])\n",
    "    column5.append(params[1])\n",
    "    column6.append(params[2])\n",
    "    column7.append(params[3])\n",
    "    \n",
    "#list of lists for the rows\n",
    "columns = list(zip(column1, column2, column3, column4, column5, column6, column7))\n",
    "\n",
    "#headers for each column\n",
    "headers = ['Neurons in HL-1', 'Neurons in HL-2', 'AUC', 'TN', 'FP', 'FN','TP']\n",
    "\n",
    "#table using the tabulate function\n",
    "table = tabulate(columns, headers, tablefmt=\"fancy_grid\")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984fc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6974e005",
   "metadata": {},
   "source": [
    "#### for 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2e2ac698",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_neurons = [(40,50,70,20),(40,50,60,40),(50,70,90,40),(40,70,40,50),(50,90,50,60)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "027898e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing data into features and labels\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['misstate']\n",
    "\n",
    "X_valid = validation_data[features]\n",
    "y_val = validation_data['misstate']\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data['misstate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "78b33b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in train set: 664\n"
     ]
    }
   ],
   "source": [
    "X_train.shape\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Number of observations in train set: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b585a",
   "metadata": {},
   "source": [
    "### For all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a7a9a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_mlp(inputs,i,j,k,l,X_train, y_train):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(inputs, i,j,k,l),\n",
    "                            random_state=42,\n",
    "                            verbose=False,\n",
    "                            learning_rate_init=0.005,\n",
    "                            activation='logistic')\n",
    "\n",
    "    # Fit data onto the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make prediction on test dataset\n",
    "    ypred = clf.predict(X_test)\n",
    "    auc = metrics.roc_auc_score(y_test, ypred)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, ypred)\n",
    "    TN, FP, FN, TP = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]  # True negatives ,False positives, False negatives, True positives\n",
    "    \n",
    "    return (auc,(TN, FP, FN, TP))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "61293286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════╤═══════════════════╤═══════════════════╤═══════════════════╤══════════╤═══════╤═══════╤══════╤══════╕\n",
      "│   Neurons in HL-1 │   Neurons in HL-2 │   Neurons in HL-3 │   Neurons in HL-4 │      AUC │    TN │    FP │   FN │   TP │\n",
      "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════╪═══════╪═══════╪══════╪══════╡\n",
      "│                40 │                50 │                70 │                20 │ 0.635429 │ 21758 │ 13147 │   92 │  169 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                50 │                60 │                40 │ 0.657703 │ 20237 │ 14668 │   69 │  192 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                70 │                90 │                40 │ 0.64207  │ 20483 │ 14422 │   79 │  182 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                70 │                40 │                50 │ 0.608031 │ 23055 │ 11850 │  116 │  145 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                90 │                50 │                60 │ 0.603138 │ 19370 │ 15535 │   91 │  170 │\n",
      "╘═══════════════════╧═══════════════════╧═══════════════════╧═══════════════════╧══════════╧═══════╧═══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "column1,column2,column3,column4,column5,column6, column7= [],[],[],[],[],[],[]\n",
    "column23,column34 = [],[]\n",
    "for i,j,k,l in hidden_layer_neurons:\n",
    "    auc,params = two_layer_mlp(42,i,j,k,l,X_train_resampled, y_train_resampled)\n",
    "    column1.append(i)\n",
    "    column2.append(j)\n",
    "    column23.append(k)\n",
    "    column34.append(l)\n",
    "    column3.append(auc)\n",
    "    column4.append(params[0])\n",
    "    column5.append(params[1])\n",
    "    column6.append(params[2])\n",
    "    column7.append(params[3])\n",
    "    \n",
    "#list of lists for the rows\n",
    "columns = list(zip(column1, column2,column23,column34, column3, column4, column5, column6, column7))\n",
    "\n",
    "#headers for each column\n",
    "headers = ['Neurons in HL-1', 'Neurons in HL-2','Neurons in HL-3', 'Neurons in HL-4', 'AUC', 'TN', 'FP', 'FN','TP']\n",
    "\n",
    "#table using the tabulate function\n",
    "table = tabulate(columns, headers, tablefmt=\"fancy_grid\")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7daf91",
   "metadata": {},
   "source": [
    "### For raw financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3ad260de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in train set: 664\n"
     ]
    }
   ],
   "source": [
    "# Split the training and testing data into features and labels\n",
    "X_train = train_data[raw_financial_items_28]\n",
    "y_train = train_data['misstate']\n",
    "\n",
    "X_valid = validation_data[raw_financial_items_28]\n",
    "y_val = validation_data['misstate']\n",
    "\n",
    "X_test = test_data[raw_financial_items_28]\n",
    "y_test = test_data['misstate'] \n",
    "\n",
    "X_train.shape\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Number of observations in train set: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9b95887e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════╤═══════════════════╤═══════════════════╤═══════════════════╤══════════╤═══════╤═══════╤══════╤══════╕\n",
      "│   Neurons in HL-1 │   Neurons in HL-2 │   Neurons in HL-3 │   Neurons in HL-4 │      AUC │    TN │    FP │   FN │   TP │\n",
      "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════╪═══════╪═══════╪══════╪══════╡\n",
      "│                40 │                50 │                70 │                20 │ 0.607497 │ 20343 │ 14562 │   96 │  165 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                50 │                60 │                40 │ 0.629537 │ 25225 │  9680 │  121 │  140 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                70 │                90 │                40 │ 0.621505 │ 22792 │ 12113 │  107 │  154 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                70 │                40 │                50 │ 0.567898 │ 25469 │  9436 │  155 │  106 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                90 │                50 │                60 │ 0.619273 │ 21700 │ 13205 │  100 │  161 │\n",
      "╘═══════════════════╧═══════════════════╧═══════════════════╧═══════════════════╧══════════╧═══════╧═══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "column1,column2,column3,column4,column5,column6, column7= [],[],[],[],[],[],[]\n",
    "column23,column34 = [],[]\n",
    "for i,j,k,l in hidden_layer_neurons:\n",
    "    auc,params = two_layer_mlp(28,i,j,k,l,X_train_resampled, y_train_resampled)\n",
    "    column1.append(i)\n",
    "    column2.append(j)\n",
    "    column23.append(k)\n",
    "    column34.append(l)\n",
    "    column3.append(auc)\n",
    "    column4.append(params[0])\n",
    "    column5.append(params[1])\n",
    "    column6.append(params[2])\n",
    "    column7.append(params[3])\n",
    "    \n",
    "#list of lists for the rows\n",
    "columns = list(zip(column1, column2,column23,column34, column3, column4, column5, column6, column7))\n",
    "\n",
    "#headers for each column\n",
    "headers = ['Neurons in HL-1', 'Neurons in HL-2','Neurons in HL-3', 'Neurons in HL-4', 'AUC', 'TN', 'FP', 'FN','TP']\n",
    "\n",
    "#table using the tabulate function\n",
    "table = tabulate(columns, headers, tablefmt=\"fancy_grid\")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5be032",
   "metadata": {},
   "source": [
    "#### Financial ratios only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c5dfe557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in train set: 664\n"
     ]
    }
   ],
   "source": [
    "# Split the training and testing data into features and labels\n",
    "X_train = train_data[financial_ratios_14]\n",
    "y_train = train_data['misstate']\n",
    "\n",
    "X_valid = validation_data[financial_ratios_14]\n",
    "y_val = validation_data['misstate']\n",
    "\n",
    "X_test = test_data[financial_ratios_14]\n",
    "y_test = test_data['misstate'] \n",
    "\n",
    "X_train.shape\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Number of observations in train set: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ae3df846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════╤═══════════════════╤═══════════════════╤═══════════════════╤══════════╤═══════╤═══════╤══════╤══════╕\n",
      "│   Neurons in HL-1 │   Neurons in HL-2 │   Neurons in HL-3 │   Neurons in HL-4 │      AUC │    TN │    FP │   FN │   TP │\n",
      "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════╪═══════╪═══════╪══════╪══════╡\n",
      "│                40 │                50 │                70 │                20 │ 0.5      │     0 │ 34905 │    0 │  261 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                50 │                60 │                40 │ 0.5      │     0 │ 34905 │    0 │  261 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                70 │                90 │                40 │ 0.605232 │ 25668 │  9237 │  137 │  124 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                40 │                70 │                40 │                50 │ 0.5      │     0 │ 34905 │    0 │  261 │\n",
      "├───────────────────┼───────────────────┼───────────────────┼───────────────────┼──────────┼───────┼───────┼──────┼──────┤\n",
      "│                50 │                90 │                50 │                60 │ 0.608321 │ 25215 │  9690 │  132 │  129 │\n",
      "╘═══════════════════╧═══════════════════╧═══════════════════╧═══════════════════╧══════════╧═══════╧═══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "column1,column2,column3,column4,column5,column6, column7= [],[],[],[],[],[],[]\n",
    "column23,column34 = [],[]\n",
    "for i,j,k,l in hidden_layer_neurons:\n",
    "    auc,params = two_layer_mlp(14,i,j,k,l,X_train_resampled, y_train_resampled)\n",
    "    column1.append(i)\n",
    "    column2.append(j)\n",
    "    column23.append(k)\n",
    "    column34.append(l)\n",
    "    column3.append(auc)\n",
    "    column4.append(params[0])\n",
    "    column5.append(params[1])\n",
    "    column6.append(params[2])\n",
    "    column7.append(params[3])\n",
    "    \n",
    "#list of lists for the rows\n",
    "columns = list(zip(column1, column2,column23,column34, column3, column4, column5, column6, column7))\n",
    "\n",
    "#headers for each column\n",
    "headers = ['Neurons in HL-1', 'Neurons in HL-2','Neurons in HL-3', 'Neurons in HL-4', 'AUC', 'TN', 'FP', 'FN','TP']\n",
    "\n",
    "#table using the tabulate function\n",
    "table = tabulate(columns, headers, tablefmt=\"fancy_grid\")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4df37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffc4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e5c2beb",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "* Build New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7310b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing data into features and labels\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['misstate']\n",
    "\n",
    "X_valid = validation_data[features]\n",
    "y_val = validation_data['misstate']\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data['misstate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "599a7370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54052, 42)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6604d38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in train set: 664\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Number of observations in train set: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ccedb118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 4ms/step - loss: 0.6595 - auc_19: 0.6813\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6198 - auc_19: 0.7240\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5942 - auc_19: 0.7496\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5837 - auc_19: 0.7586\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5773 - auc_19: 0.7641\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5741 - auc_19: 0.7655\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5598 - auc_19: 0.7802\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5518 - auc_19: 0.7837\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5488 - auc_19: 0.7892\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5435 - auc_19: 0.7894\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5467 - auc_19: 0.7920\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5328 - auc_19: 0.8038\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5315 - auc_19: 0.8028\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5258 - auc_19: 0.8098\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5145 - auc_19: 0.8200\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5155 - auc_19: 0.8177\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5133 - auc_19: 0.8186\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5097 - auc_19: 0.8216\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4943 - auc_19: 0.8345\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5062 - auc_19: 0.8277\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4975 - auc_19: 0.8305\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4845 - auc_19: 0.8438\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4719 - auc_19: 0.8530\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4727 - auc_19: 0.8548\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4616 - auc_19: 0.8623\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4654 - auc_19: 0.8552\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4621 - auc_19: 0.8594\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4604 - auc_19: 0.8627\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4516 - auc_19: 0.8668\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4391 - auc_19: 0.8759\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4231 - auc_19: 0.8872\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4212 - auc_19: 0.8882\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4184 - auc_19: 0.8904\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4159 - auc_19: 0.8894\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4092 - auc_19: 0.8941\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3927 - auc_19: 0.9058\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3800 - auc_19: 0.9138\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3851 - auc_19: 0.9072\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3963 - auc_19: 0.9012\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3758 - auc_19: 0.9146\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4991 - auc_19: 0.8935\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3801 - auc_19: 0.9106\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3533 - auc_19: 0.9270\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3563 - auc_19: 0.9227\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3573 - auc_19: 0.9229\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3494 - auc_19: 0.9252\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3417 - auc_19: 0.9302\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3207 - auc_19: 0.9389\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3146 - auc_19: 0.9441\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3128 - auc_19: 0.9424\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3086 - auc_19: 0.9431\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2950 - auc_19: 0.9519\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2928 - auc_19: 0.9518\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2804 - auc_19: 0.9561\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2709 - auc_19: 0.9594\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2780 - auc_19: 0.9549\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2981 - auc_19: 0.9467\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2735 - auc_19: 0.9568\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2454 - auc_19: 0.9690\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2453 - auc_19: 0.9666\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2347 - auc_19: 0.9712\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2533 - auc_19: 0.9633\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3001 - auc_19: 0.9446\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2994 - auc_19: 0.9525\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2992 - auc_19: 0.9499\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2501 - auc_19: 0.9678\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2270 - auc_19: 0.9736\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2128 - auc_19: 0.9773\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2188 - auc_19: 0.9758\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2054 - auc_19: 0.9790\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2028 - auc_19: 0.9792\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1980 - auc_19: 0.9801\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1916 - auc_19: 0.9822\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2001 - auc_19: 0.9781\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1896 - auc_19: 0.9815\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2137 - auc_19: 0.9733\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1896 - auc_19: 0.9817\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1977 - auc_19: 0.9779\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1822 - auc_19: 0.9828\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1604 - auc_19: 0.9875\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1686 - auc_19: 0.9862\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1561 - auc_19: 0.9888\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1760 - auc_19: 0.9834\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1662 - auc_19: 0.9859\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1578 - auc_19: 0.9868\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1532 - auc_19: 0.9888\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1586 - auc_19: 0.9869\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1389 - auc_19: 0.9913\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1572 - auc_19: 0.9869\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1705 - auc_19: 0.9836\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1358 - auc_19: 0.9907\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1302 - auc_19: 0.9913\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1297 - auc_19: 0.9926\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1530 - auc_19: 0.9868\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1258 - auc_19: 0.9918\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1289 - auc_19: 0.9915\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1485 - auc_19: 0.9883\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1199 - auc_19: 0.9922\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1356 - auc_19: 0.9897\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1235 - auc_19: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d801566c80>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 7, 6, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 7, 6, 1)\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(7, 6, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[AUC()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_resampled, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "03aeb488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099/1099 [==============================] - 3s 2ms/step\n",
      "AUC: 0.5679\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2c1b943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 28)\n",
      "18592\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c84273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f12e40a9",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "05a63db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing data into features and labels\n",
    "X_train = train_data[raw_financial_items_28]\n",
    "y_train = train_data['misstate']\n",
    "\n",
    "X_valid = validation_data[raw_financial_items_28]\n",
    "y_val = validation_data['misstate']\n",
    "\n",
    "X_test = test_data[raw_financial_items_28]\n",
    "y_test = test_data['misstate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8b5ed232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54052, 28)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5f20f103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in train set: 664\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Number of observations in train set: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0d653ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 3ms/step - loss: 0.6707 - auc_20: 0.5688\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6606 - auc_20: 0.5801\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6583 - auc_20: 0.5711\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6500 - auc_20: 0.6006\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6462 - auc_20: 0.6148\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6456 - auc_20: 0.6287\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6421 - auc_20: 0.6227\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6400 - auc_20: 0.6433\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6399 - auc_20: 0.6103\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6381 - auc_20: 0.6407\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6324 - auc_20: 0.6603\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6287 - auc_20: 0.6697\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6263 - auc_20: 0.6855\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6224 - auc_20: 0.7004\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6214 - auc_20: 0.6894\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6207 - auc_20: 0.6833\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6143 - auc_20: 0.6988\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6066 - auc_20: 0.7258\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6117 - auc_20: 0.6977\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6033 - auc_20: 0.7173\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5980 - auc_20: 0.7324\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5901 - auc_20: 0.7331\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5929 - auc_20: 0.7185\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5857 - auc_20: 0.7353\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5838 - auc_20: 0.7430\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5810 - auc_20: 0.7425\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5741 - auc_20: 0.7534\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5781 - auc_20: 0.7423\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5684 - auc_20: 0.7656\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5838 - auc_20: 0.7267\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5608 - auc_20: 0.7772\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5667 - auc_20: 0.7482\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5631 - auc_20: 0.7683\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5597 - auc_20: 0.7575\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5486 - auc_20: 0.7908\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5511 - auc_20: 0.7755\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5391 - auc_20: 0.7855\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5415 - auc_20: 0.7787\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5388 - auc_20: 0.7898\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5354 - auc_20: 0.7919\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5406 - auc_20: 0.7856\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5399 - auc_20: 0.7815\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5326 - auc_20: 0.7908\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5253 - auc_20: 0.8035\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5237 - auc_20: 0.8091\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5174 - auc_20: 0.8090\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5217 - auc_20: 0.7995\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5110 - auc_20: 0.8199\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5296 - auc_20: 0.7891\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5156 - auc_20: 0.8129\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5109 - auc_20: 0.8152\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5095 - auc_20: 0.8211\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5234 - auc_20: 0.7926\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5038 - auc_20: 0.8184\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5058 - auc_20: 0.8177\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5869 - auc_20: 0.7853\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5752 - auc_20: 0.7761\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5139 - auc_20: 0.8076\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5081 - auc_20: 0.8128\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4991 - auc_20: 0.8271\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4958 - auc_20: 0.8263\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5058 - auc_20: 0.8099\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5018 - auc_20: 0.8141\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4941 - auc_20: 0.8221\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4892 - auc_20: 0.8327\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4946 - auc_20: 0.8240\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4867 - auc_20: 0.8314\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4874 - auc_20: 0.8328\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4839 - auc_20: 0.8331\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4896 - auc_20: 0.8223\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4955 - auc_20: 0.8165\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4861 - auc_20: 0.8307\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4839 - auc_20: 0.8325\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4820 - auc_20: 0.8339\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4786 - auc_20: 0.8375\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4835 - auc_20: 0.8315\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4795 - auc_20: 0.8347\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4709 - auc_20: 0.8459\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4688 - auc_20: 0.8493\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4723 - auc_20: 0.8437\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4691 - auc_20: 0.8439\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4774 - auc_20: 0.8368\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4754 - auc_20: 0.8405\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4649 - auc_20: 0.8483\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4705 - auc_20: 0.8439\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4711 - auc_20: 0.8416\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4817 - auc_20: 0.8282\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4689 - auc_20: 0.8442\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4605 - auc_20: 0.8540\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4639 - auc_20: 0.8460\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4633 - auc_20: 0.8496\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4645 - auc_20: 0.8446\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4619 - auc_20: 0.8471\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4547 - auc_20: 0.8577\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4543 - auc_20: 0.8599\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4629 - auc_20: 0.8457\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4669 - auc_20: 0.8417\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4675 - auc_20: 0.8420\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4564 - auc_20: 0.8567\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4514 - auc_20: 0.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d802347dc0>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 7, 4, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 7, 4, 1)\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (1, 2), activation='relu', input_shape=(7, 4, 1)))\n",
    "model.add(layers.ZeroPadding2D(padding=((0, 0), (0, 1))))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (1, 2), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[AUC()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_resampled, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5cfdae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099/1099 [==============================] - 3s 2ms/step\n",
      "AUC: 0.6512\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8871f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d3792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b28aaf36",
   "metadata": {},
   "source": [
    "#### Performance Evaluation over 2003-2008 sample\n",
    "\n",
    "| Input Var | Method | Neurons | Activation Func| Learning rate  | AUC |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "|   28 Raw Financial Items  |   MLP - 1  |  70   |   Logistic  |   0.003 | 0.6627|\n",
    "|     |   MLP - 2 |   (40,60)  |   Logistic  |   0.003 |  0.627567  |\n",
    "|    |   MLP - 4  |   (40,50,60,40)  |   Logitsic  |   0.003  |  0.629537  |\n",
    "|    |   CNN  |     |     |  |   0.6512  |\n",
    "|   28 Raw + 14 Finan Ratios |   MLP - 1  |  70   |   Logistic  |   0.005|   0.648682|\n",
    "|     |   MLP - 2 |   (40,60)  |   Logistic  |   0.003 | 0.62822  |\n",
    "|    |   MLP - 4  |   (40,60,50,40)  |   Logitsic  |   0.003  |  0.657703  |\n",
    "|    |   CNN  |     |     |     |    0.5679  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f729da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
